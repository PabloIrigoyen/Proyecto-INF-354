# -*- coding: utf-8 -*-
"""Entrenamiento supervisado codigo 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oSxllCIfTeEalt6vMFagfhLtjOrSLxUv
"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.feature_selection import VarianceThreshold
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import pandas as pd

# Cargar el dataset
def load_data(filepath):
    df = pd.read_csv(filepath)
    return df

# Preprocesamiento de los datos
def preprocess_data(df):
    # Asumimos que 'target' es la columna objetivo
    X = df.drop(columns='target')
    y = df['target']

     # Eliminar caracter铆sticas de baja varianza
    vt = VarianceThreshold(threshold=0.01)  # Umbral ajustable
    X_vt = vt.fit_transform(X)
    print(f"Selecci贸n de caracter铆sticas aplicada: {X_vt.shape[1]} caracter铆sticas retenidas.")
    print("Datos preprocesados correctamente.\n")
    return X_vt, y

# Aplicar Min-Max Scaling
def apply_minmax_scaling(X):
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    print(f"Normlizaci贸n (Min-Max-Scalling) aplicada con resutlado:\n{X_scaled}")
    return X_scaled

# Estandarizaci贸n
def apply_z_core(X):
    scaler = StandardScaler()
    X_standardized = scaler.fit_transform(X)
    print(f"Estandarizaci贸n (Z-score Scalling) aplicada con resultado: {X_standardized.shape[1]}")
    return X_standardized

# Dividir los datos en conjunto de entrenamiento y prueba
def split_data(X, y, test_size=0.2):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    print(f"Datos divididos: {len(X_train)} para entrenamiento y {len(X_test)} para prueba.")
    return X_train, X_test, y_train, y_test

# Balanceo de clases con SMOTE
def balance_data(X_train, y_train):
    smote = SMOTE(random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
    return X_train_res, y_train_res

# Entrenamiento del modelo con RandomForest
def train_random_forest(X_train, y_train):
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    return model

# Evaluaci贸n del modelo
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)
    print(f'Exactitud del modelo: {accuracy:.4f}')
    return accuracy, cm

# Visualizaci贸n de la matriz de confusi贸n
def plot_confusion_matrix(cm):
    plt.figure(figsize=(6,6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Matriz de Confusi贸n')
    plt.colorbar()
    tick_marks = range(len(cm))
    plt.xticks(tick_marks, tick_marks)
    plt.yticks(tick_marks, tick_marks)
    plt.ylabel('Etiqueta Real')
    plt.xlabel('Etiqueta Predicha')
    plt.show()

# Nueva funci贸n para pruebas con nuevos datos
def pruebas(model, nuevos_datos):
    """    
    Par谩metros:
    - model: Modelo entrenado.
    - nuevos_datos: Lista con los valores de las caracter铆sticas en el mismo orden que el conjunto de entrenamiento.
    
    Retorno:
    - Mensaje indicando si la persona padece o no problemas.
    """
    nuevos_datos_df = pd.DataFrame([nuevos_datos])  # Convertimos los nuevos datos a DataFrame
    prediccion = model.predict(nuevos_datos_df)
    if prediccion[0] == 1:
        resultado = "Usted padece problemas"
    else:
        resultado = "Usted no padece ninguna afecci贸n"
    print(f"Predicci贸n para los datos {nuevos_datos}: {resultado}")
    return resultado

# Funci贸n principal
def main():
    # Cargar los datos
    df = load_data('heart.csv')
    
    # Preprocesamiento
    X, y = preprocess_data(df)
    
    # Aplicar Min-Max Scaling
    X_scaled = apply_minmax_scaling(X)

    print("Splits - Primera ejecuci贸n (0.8 - 0.2)\n")
    
    # Divisi贸n de datos 0.8-0.2
    X_train, X_test, y_train, y_test = split_data(X_scaled, y, test_size=0.2)
    
    # Balanceo de clases (opcional)
    X_train_res, y_train_res = balance_data(X_train, y_train)
    
    # Entrenamiento del modelo
    model = train_random_forest(X_train_res, y_train_res)
    
    # Evaluaci贸n
    accuracy, cm = evaluate_model(model, X_test, y_test)
    
    # Probando con nuevos datos
    print("\nPruebas con nuevos datos\n")
    nuevos_datos = [57, 1, 3, 140, 241, 0, 1, 123, 1, 0.2, 1, 0, 3]  # Datos de ejemplo
    pruebas(model, nuevos_datos)
    
    # Matriz de confusi贸n
    plot_confusion_matrix(cm)

    print("\nSplits - Segunda ejecuci贸n(0.5 - 0.5)\n")

    

    # Divisi贸n de datos 0.5-0.5
    X_train, X_test, y_train, y_test = split_data(X_scaled, y, test_size=0.5)
    
      # Balanceo de clases (opcional)
    X_train_res, y_train_res = balance_data(X_train, y_train)
    
    # Entrenamiento del modelo
    model = train_random_forest(X_train_res, y_train_res)
    
    # Evaluaci贸n
    accuracy, cm = evaluate_model(model, X_test, y_test)

    # Probando con nuevos datos
    print("\nPruebas con nuevos datos\n")
    nuevos_datos = [57, 1, 3, 140, 241, 0, 1, 123, 1, 0.2, 1, 0, 3]  # Datos de ejemplo
    pruebas(model, nuevos_datos)
    
    # Matriz de confusi贸n
    plot_confusion_matrix(cm)
if __name__ == "__main__":
    main()
